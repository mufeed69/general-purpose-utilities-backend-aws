service: s3-file-processor

provider:
  name: aws
  runtime: nodejs20.x  # Or use python3.9 for a Python Lambda
  region: ap-south-1  # Your AWS region
  environment:
      DATABASE_TABLE: !Ref DataTable  # DynamoDB table name
  iamRoleStatements:
    # S3 permissions for upload and list
    - Effect: Allow
      Action:
        - s3:*
      Resource:
        - arn:aws:s3:::mufeed-s3-bucket/*
    - Effect: Allow
      Action:
        - dynamodb:*
      Resource:
        - !GetAtt DataTable.Arn
      

functions:
  processFile:
    handler: handlers/file_processer.handler  # The Lambda handler method
    layers: arn:aws:lambda:ap-south-1:625209709588:layer:nodeLayer:1
    events:
      - s3:
          bucket: mufeed-s3-bucket  # S3 bucket that will trigger the Lambda
          event: s3:ObjectCreated:*  # Trigger the Lambda on object creation (file upload)
          rules:
            - suffix: .csv  # Only trigger for CSV files
          existing: true

resources:
  Resources:
    # DynamoDB Table to store the parsed data from the CSV file
    DataTable:
      Type: AWS::DynamoDB::Table
      Properties:
        TableName: FileData
        AttributeDefinitions:
          - AttributeName: "jobId"
            AttributeType: "S"
        KeySchema:
          - AttributeName: "jobId"
            KeyType: "HASH"
        ProvisionedThroughput:
          ReadCapacityUnits: 5
          WriteCapacityUnits: 5

